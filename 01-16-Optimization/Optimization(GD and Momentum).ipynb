{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "314a0742",
   "metadata": {},
   "source": [
    "## Gradient Desent\n",
    "\n",
    "### $\\theta_{W_t} = \\theta_{W_{t-1}} - \\eta \\frac{\\partial L}{\\partial W_{t-1}} = \\theta_{W_{t-1}} - \\eta {\\nabla}W_{t-1}$  \n",
    "\n",
    "## Momentum\n",
    "### $v_t = \\gamma v_{t-1} +  \\nabla W_{t-1} $\n",
    "### $ W_t = W_{t-1} - \\eta v_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515f536a",
   "metadata": {},
   "source": [
    "### Fully-connected Layer(Dense Layer)\n",
    "## $H(x) = Wx + b$\n",
    "### - x = [1,2,3]\n",
    "### - y = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07293903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "93717dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_seed =2\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e56b769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 앞의 1 = 입력 노드의 개수(100), 뒤의 1 = 출력 노드의 개수(히든층 혹은 출력층)(10) = 1\n",
    "        self.linear = nn.Linear(1,1,bias=True) # W = [1] , B = [1]\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8c5d40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model()\n",
    "model2 = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "faf5a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(np.array([[1],[2],[3],[4],[5]]),dtype=torch.float)\n",
    "y_train = torch.tensor(np.array([[1],[2],[3],[4],[5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0994798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mean_squred_error(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x,y):\n",
    "        return torch.mean(torch.square(x-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "885b41b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = mean_squred_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c3e67f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optim1 = torch.optim.SGD(model1.parameters(),lr=learning_rate)\n",
    "optim2 = torch.optim.SGD(model2.parameters(),lr=learning_rate,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0ceb22e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2294]], requires_grad=True) Parameter containing:\n",
      "tensor([-0.2380], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.2742]], requires_grad=True) Parameter containing:\n",
      "tensor([-0.0511], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model1.linear.weight,model1.linear.bias)\n",
    "print(model2.linear.weight,model2.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e1ec7973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(model1.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8cdd3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2294]], requires_grad=True) Parameter containing:\n",
      "tensor([-0.2380], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.2294]], requires_grad=True) Parameter containing:\n",
      "tensor([-0.2380], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model1.linear.weight,model1.linear.bias)\n",
    "print(model2.linear.weight,model2.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2ccf5",
   "metadata": {},
   "source": [
    "### Initialization Weight and Bias\n",
    "#### - W = 0.2294\n",
    "#### - B = -0.2380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b0c3d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim1.zero_grad()\n",
    "\n",
    "pred = model1(x_train)\n",
    "\n",
    "loss = cost(pred,y_train)\n",
    "\n",
    "loss.backward()\n",
    "optim1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7eb4e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim2.zero_grad()\n",
    "\n",
    "pred = model2(x_train)\n",
    "\n",
    "loss = cost(pred,y_train)\n",
    "loss.backward()\n",
    "optim2.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8f77a",
   "metadata": {},
   "source": [
    "### Print Gradient of Weights and Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b2e0cd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-18.3813]]) tensor([-5.0996])\n"
     ]
    }
   ],
   "source": [
    "print(model1.linear.weight.grad,model1.linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8bde30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-18.3813]]) tensor([-5.0996])\n"
     ]
    }
   ],
   "source": [
    "print(model2.linear.weight.grad,model2.linear.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619bf496",
   "metadata": {},
   "source": [
    "## Gradient Desent\n",
    "\n",
    "### $\\theta_{W_t} = \\theta_{W_{t-1}} - \\eta \\frac{\\partial L}{\\partial W_{t-1}} = \\theta_{W_{t-1}} - \\eta {\\nabla}W_{t-1}$  \n",
    "\n",
    "## Momentum\n",
    "### $v_t = \\gamma v_{t-1} +  \\nabla W_{t-1} $\n",
    "### $ W_t = W_{t-1} - \\eta v_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7d64a4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2.0675]], requires_grad=True) Parameter containing:\n",
      "tensor([0.2720], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[2.0675]], requires_grad=True) Parameter containing:\n",
      "tensor([0.2720], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model1.linear.weight,model1.linear.bias)\n",
    "print(model2.linear.weight,model2.linear.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaf2db4",
   "metadata": {},
   "source": [
    "### $ v_{t-1} = 0$\n",
    "### $v_t = 0.9 \\times 0 + (-18.3813)  = -18.3813$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6ee29556",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim1.zero_grad()\n",
    "\n",
    "pred = model1(x_train)\n",
    "\n",
    "loss = cost(pred,y_train)\n",
    "loss.backward()\n",
    "optim1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6515b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim2.zero_grad()\n",
    "\n",
    "pred = model2(x_train)\n",
    "\n",
    "loss = cost(pred,y_train)\n",
    "loss.backward()\n",
    "optim2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bc031a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25.1173]]) tensor([6.9491])\n",
      "tensor([[25.1173]]) tensor([6.9491])\n"
     ]
    }
   ],
   "source": [
    "print(model1.linear.weight.grad,model1.linear.bias.grad)\n",
    "print(model2.linear.weight.grad,model2.linear.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950da03d",
   "metadata": {},
   "source": [
    "## GD\n",
    "\n",
    "### $ W_t = W_{t-1} - (0.1 \\times 25.1173)$\n",
    "### $ W_t = 2.0675 - (0.1 \\times 25.1173) = 2.0675 - 0.857413 = -0.44423$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3d41f",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "\n",
    "### $ v_{t-1} = -18.3813$\n",
    "### $v_t = 0.9 \\times -18.3813 + 25.1173  = -16.54317 + 25.1173 = 8.57413$\n",
    "### $ W_t = W_{t-1} - (0.1 \\times 8.57413)$\n",
    "### $ W_t = 2.0675 - (0.1 \\times 8.57413) = 2.0675 - 0.857413 = 1.210087$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bcfa6213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.4442]], requires_grad=True) Parameter containing:\n",
      "tensor([-0.4229], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1.2101]], requires_grad=True) Parameter containing:\n",
      "tensor([0.0360], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model1.linear.weight,model1.linear.bias)\n",
    "print(model2.linear.weight,model2.linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e7742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p38",
   "language": "python",
   "name": "pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

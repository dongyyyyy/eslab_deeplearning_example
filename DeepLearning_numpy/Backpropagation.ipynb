{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b3ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import model as NN\n",
    "import dataloader as DL\n",
    "import loss_function as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb32055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data file\n",
    "\n",
    "infile = open('../dataset/mnist.pkl','rb')\n",
    "mnist_data = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab1b129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Xtest', 'ytest', 'Xtrain', 'ytrain'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23cd860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 20\n",
    "\n",
    "train_loader = DL.dataLoader(mnist_data['Xtrain'], mnist_data['ytrain'], batchsize)\n",
    "test_loader = DL.dataLoader(mnist_data['Xtest'], mnist_data['ytest'], batchsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea2a84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN.Network(400, 10, [50, 20, 30 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340ebb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th training loss = 2.300588310688372\n",
      "1th training accuracy = [0.13625]\n",
      "2th training loss = 2.28508780857587\n",
      "2th training accuracy = [0.17125]\n",
      "3th training loss = 2.242534100477234\n",
      "3th training accuracy = [0.19175]\n",
      "4th training loss = 2.04445884765439\n",
      "4th training accuracy = [0.29025]\n",
      "5th training loss = 1.548676263573644\n",
      "5th training accuracy = [0.44125]\n",
      "6th training loss = 1.202538247524273\n",
      "6th training accuracy = [0.5755]\n",
      "7th training loss = 0.9675340239028206\n",
      "7th training accuracy = [0.704]\n",
      "8th training loss = 0.7265374437516712\n",
      "8th training accuracy = [0.7905]\n",
      "9th training loss = 0.5815561130311377\n",
      "9th training accuracy = [0.82925]\n",
      "10th training loss = 0.48799392038011385\n",
      "10th training accuracy = [0.8635]\n",
      "11th training loss = 0.4318121249591971\n",
      "11th training accuracy = [0.87875]\n",
      "12th training loss = 0.3890425238329508\n",
      "12th training accuracy = [0.8915]\n",
      "13th training loss = 0.35846128893400975\n",
      "13th training accuracy = [0.90025]\n",
      "14th training loss = 0.3285436973435765\n",
      "14th training accuracy = [0.91025]\n",
      "15th training loss = 0.3047833733996515\n",
      "15th training accuracy = [0.917]\n",
      "16th training loss = 0.2823534508731412\n",
      "16th training accuracy = [0.92225]\n",
      "17th training loss = 0.26306957925769714\n",
      "17th training accuracy = [0.923]\n",
      "18th training loss = 0.24229235304126712\n",
      "18th training accuracy = [0.92825]\n",
      "19th training loss = 0.22955270682878928\n",
      "19th training accuracy = [0.93575]\n",
      "20th training loss = 0.21207832724946166\n",
      "20th training accuracy = [0.94425]\n",
      "21th training loss = 0.1975423665296854\n",
      "21th training accuracy = [0.9465]\n",
      "22th training loss = 0.18764545524276602\n",
      "22th training accuracy = [0.9465]\n",
      "23th training loss = 0.1733784070078383\n",
      "23th training accuracy = [0.95]\n",
      "24th training loss = 0.16695627527345433\n",
      "24th training accuracy = [0.9535]\n",
      "25th training loss = 0.15450250270609373\n",
      "25th training accuracy = [0.9545]\n",
      "26th training loss = 0.144034690109004\n",
      "26th training accuracy = [0.9575]\n",
      "27th training loss = 0.13283453944416854\n",
      "27th training accuracy = [0.964]\n",
      "28th training loss = 0.12461950521628985\n",
      "28th training accuracy = [0.96775]\n",
      "29th training loss = 0.1178906642094921\n",
      "29th training accuracy = [0.969]\n",
      "30th training loss = 0.11204215661397045\n",
      "30th training accuracy = [0.97]\n",
      "31th training loss = 0.10330740975952915\n",
      "31th training accuracy = [0.974]\n",
      "32th training loss = 0.10020186546689931\n",
      "32th training accuracy = [0.97325]\n",
      "33th training loss = 0.09117951046828054\n",
      "33th training accuracy = [0.97625]\n",
      "34th training loss = 0.08299931527287847\n",
      "34th training accuracy = [0.97925]\n",
      "35th training loss = 0.07810257563868675\n",
      "35th training accuracy = [0.97975]\n",
      "36th training loss = 0.07396313694682671\n",
      "36th training accuracy = [0.981]\n",
      "37th training loss = 0.07103052665764516\n",
      "37th training accuracy = [0.983]\n",
      "38th training loss = 0.06370380966456402\n",
      "38th training accuracy = [0.9845]\n",
      "39th training loss = 0.05963425780677685\n",
      "39th training accuracy = [0.988]\n",
      "40th training loss = 0.05514348421827107\n",
      "40th training accuracy = [0.988]\n",
      "41th training loss = 0.05333651330709249\n",
      "41th training accuracy = [0.98875]\n",
      "42th training loss = 0.04843334867047754\n",
      "42th training accuracy = [0.9895]\n",
      "43th training loss = 0.04581213589493326\n",
      "43th training accuracy = [0.9925]\n",
      "44th training loss = 0.04237585829118496\n",
      "44th training accuracy = [0.9905]\n",
      "45th training loss = 0.0425569592548173\n",
      "45th training accuracy = [0.99175]\n",
      "46th training loss = 0.03939329636313575\n",
      "46th training accuracy = [0.9915]\n",
      "47th training loss = 0.03545439178955267\n",
      "47th training accuracy = [0.9935]\n",
      "48th training loss = 0.033627299727753746\n",
      "48th training accuracy = [0.994]\n",
      "49th training loss = 0.030625285162090808\n",
      "49th training accuracy = [0.994]\n",
      "50th training loss = 0.028833297378052417\n",
      "50th training accuracy = [0.995]\n",
      "51th training loss = 0.02662713378030335\n",
      "51th training accuracy = [0.9955]\n",
      "52th training loss = 0.024228103148537898\n",
      "52th training accuracy = [0.997]\n",
      "53th training loss = 0.02285590665383291\n",
      "53th training accuracy = [0.99675]\n",
      "54th training loss = 0.02245209491690945\n",
      "54th training accuracy = [0.99675]\n",
      "55th training loss = 0.020064162021150193\n",
      "55th training accuracy = [0.99775]\n",
      "56th training loss = 0.018574533833541695\n",
      "56th training accuracy = [0.99725]\n",
      "57th training loss = 0.017270456732794693\n",
      "57th training accuracy = [0.99775]\n",
      "58th training loss = 0.016776437547846502\n",
      "58th training accuracy = [0.9975]\n",
      "59th training loss = 0.015076480678267883\n",
      "59th training accuracy = [0.9975]\n",
      "60th training loss = 0.013675497327844916\n",
      "60th training accuracy = [0.9985]\n",
      "61th training loss = 0.01275041020977142\n",
      "61th training accuracy = [0.999]\n",
      "62th training loss = 0.011912732525318255\n",
      "62th training accuracy = [0.99925]\n",
      "63th training loss = 0.011590233645753487\n",
      "63th training accuracy = [0.999]\n",
      "64th training loss = 0.009976598522967972\n",
      "64th training accuracy = [0.9995]\n",
      "65th training loss = 0.010611507048694456\n",
      "65th training accuracy = [0.99875]\n",
      "66th training loss = 0.00907731646053277\n",
      "66th training accuracy = [0.9995]\n",
      "67th training loss = 0.008731360572950491\n",
      "67th training accuracy = [0.99925]\n",
      "68th training loss = 0.008451751829334697\n",
      "68th training accuracy = [0.9995]\n",
      "69th training loss = 0.007816716067904421\n",
      "69th training accuracy = [0.9995]\n",
      "70th training loss = 0.007355116365240653\n",
      "70th training accuracy = [0.9995]\n",
      "71th training loss = 0.007094659220102242\n",
      "71th training accuracy = [1.]\n",
      "72th training loss = 0.006468975071078462\n",
      "72th training accuracy = [1.]\n",
      "73th training loss = 0.006434843413246566\n",
      "73th training accuracy = [1.]\n",
      "74th training loss = 0.006083064187188302\n",
      "74th training accuracy = [1.]\n",
      "75th training loss = 0.005734598846135086\n",
      "75th training accuracy = [1.]\n",
      "76th training loss = 0.0056376992227426806\n",
      "76th training accuracy = [1.]\n",
      "77th training loss = 0.0053062631385951565\n",
      "77th training accuracy = [1.]\n",
      "78th training loss = 0.005062835249118999\n",
      "78th training accuracy = [1.]\n",
      "79th training loss = 0.004878432223669757\n",
      "79th training accuracy = [1.]\n",
      "80th training loss = 0.004630795083186653\n",
      "80th training accuracy = [1.]\n",
      "81th training loss = 0.004507055199937775\n",
      "81th training accuracy = [1.]\n",
      "82th training loss = 0.004268650543974241\n",
      "82th training accuracy = [1.]\n",
      "83th training loss = 0.004178292092056667\n",
      "83th training accuracy = [1.]\n",
      "84th training loss = 0.003901373890949018\n",
      "84th training accuracy = [1.]\n",
      "85th training loss = 0.0038107242558712384\n",
      "85th training accuracy = [1.]\n",
      "86th training loss = 0.0037303614401966636\n",
      "86th training accuracy = [1.]\n",
      "87th training loss = 0.003649181821365664\n",
      "87th training accuracy = [1.]\n",
      "88th training loss = 0.003440771646148787\n",
      "88th training accuracy = [1.]\n",
      "89th training loss = 0.0033656248579325147\n",
      "89th training accuracy = [1.]\n",
      "90th training loss = 0.003269854031151183\n",
      "90th training accuracy = [1.]\n",
      "91th training loss = 0.003161571927985464\n",
      "91th training accuracy = [1.]\n",
      "92th training loss = 0.0030406477688376017\n",
      "92th training accuracy = [1.]\n",
      "93th training loss = 0.003014806555721131\n",
      "93th training accuracy = [1.]\n",
      "94th training loss = 0.0028868803726285826\n",
      "94th training accuracy = [1.]\n",
      "95th training loss = 0.002815893775710279\n",
      "95th training accuracy = [1.]\n",
      "96th training loss = 0.0027538273729761837\n",
      "96th training accuracy = [1.]\n",
      "97th training loss = 0.0026883823067670176\n",
      "97th training accuracy = [1.]\n",
      "98th training loss = 0.0025916613754962013\n",
      "98th training accuracy = [1.]\n",
      "99th training loss = 0.0025537511961925986\n",
      "99th training accuracy = [1.]\n",
      "100th training loss = 0.0024915444237255517\n",
      "100th training accuracy = [1.]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "training_loss = {}\n",
    "training_accuracy = {}\n",
    "num_train_batches = mnist_data['Xtrain'].shape[0] / batchsize\n",
    "alpha = 0.02\n",
    "\n",
    "ind = 0\n",
    "for e in range(1, num_epochs + 1):\n",
    "    train_loader = DL.dataLoader(mnist_data['Xtrain'], mnist_data['ytrain'], batchsize)\n",
    "    training_loss.update({e: 0.0})\n",
    "    training_accuracy.update({e: 0.0})\n",
    "\n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model.forward(image)\n",
    "        # Backward pass\n",
    "        model.backward(image, label)\n",
    "        # Update\n",
    "        model.update(alpha)\n",
    "        # Calculate training loss and accuracy (Homework, see lecture)\n",
    "\n",
    "        training_loss[e] += loss.crossentropy(pred, label)\n",
    "        # print(NN.crossentropy(NN.softmax(pred), label_onehot))\n",
    "        #         print(NN.crossentropy(pred,label))\n",
    "        training_accuracy[e] += loss.ave_accuracy(pred, label)\n",
    "        # exit(1)\n",
    "    #     break\n",
    "\n",
    "    # At each epoch 'e', print training loss and accuracy (homework)\n",
    "    training_loss[e] = training_loss[e] / num_train_batches\n",
    "    training_accuracy[e] = training_accuracy[e] / num_train_batches\n",
    "    print(f'{e}th training loss = {training_loss[e]}\\n{e}th training accuracy = {training_accuracy[e]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8acb594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(training_loss.keys()), list(training_loss.values()))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639562f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_p38",
   "language": "python",
   "name": "pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
